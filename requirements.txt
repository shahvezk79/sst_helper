# Core (all platforms)
pandas>=2.0
pyarrow>=14.0
numpy>=1.24
huggingface_hub>=0.23
streamlit>=1.35

# Cloud compute — DeepInfra embedding, reranking, and generation
openai>=1.30      # OpenAI-compatible client (used for DeepInfra embedding + generation)
requests>=2.31    # Used for DeepInfra reranker (native inference endpoint)

# Local inference — Apple Silicon only (install separately on M-series Macs)
# These are required only when using compute_mode="local" (MLX backend).
# Skip on Linux/Windows/non-Apple-Silicon platforms.
# mlx>=0.22.0
# mlx-lm>=0.20.0
# transformers>=4.40
# tokenizers>=0.19
